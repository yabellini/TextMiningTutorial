---
title: "Introducción a Text Mining"
output:
  learnr::tutorial:
    language: es
    progressive: true
    allow_skip: true
runtime: shiny_prerendered
tutorial:
  version: 1.0
description: "Tutorial de introducción al paquete tidytext para trabajar con texto"
---

```{r setup, include=FALSE}
library(learnr)
knitr::opts_chunk$set(echo = FALSE)
library(tidytext)
library(dplyr)
library(tidyr)
library(tibble)
library(ggplot2)
library(magrittr)
```


## El formato tidy para texto

El uso de principios de datos ordenados es una forma poderosa para hacer que el manejo de datos sea más fácil y efectivo. Esto también aplica cuando trabajamos con texto. Los datos ordenados o **tidy** tienen una estructura específica:

  * Cada _variable_ es una _columna_.
  * Cada _observación_ es una _fila_.
  * Cada _tipo de unidad de observación_ es una _tabla_.

Teniendo en cuenta esta definición, el formato de texto ordenado (tidy text) es una _tabla_ con un _token_ por _fila_. 

Un _token_ es una _unidad significativa de texto_, como una _palabra_, que queremos usar para el análisis, y la _tokenización_ es el proceso de _dividir el texto_ en _tokens_. 

Para una minería de texto ordenada, el _token_ que se almacena en cada _fila_ suele ser _una sola palabra_, pero también puede ser un _n-grama_, una _oración_ o un _párrafo_. El paquete `tidytext`, proporciona las funciones para tokenizar por unidades de texto de uso común como las mencionadas y convertirlas a un formato de un término por fila.

Además, contar con el texto en un formato tidy, nos permitirá usar los paquetes del _tidyverse_ para trabajar con los datos.

### Trabajando con texto 

Vamos a conocer las funciones fundamentales para ordenar nuestro texto, sigamos el orden de los siguientes ejercicios para ver como trabaja la función `unnest_tokens`. 

María Elena Walsh escribió un hermoso libro llamado _Zoo Loco_ que contiene _limericks_: versos que riman y no tienen mucho sentido y por eso son muy graciosos.  _Nota: vamos a usar el texto sin acentos para evitar problemas de codificación, pero más adelante veremos como resolverlos_

Ejecuta el siguiente código para generar un _vector de caracteres_ en R con el limericks.



```{r vector_texto, exercise=TRUE}

text <- c("En Tucuman vivia una tortuga",
          "viejisima pero sin una sola arruga,",
          "porque en toda ocasion",
          "tuvo la precaucion",
          "de comer bien planchada la lechuga.")

text
```

### Mensaje

Buen trabajo! Usaremos fragmentos de código interactivos como este en el tutorial. Siempre que encuentres uno, puedes hacer clic en _Ejecutar código_ para ejecutar el código escrito. Si hay un botón _Pista_ o _Solución_, puedes hacer clic para recibir ayuda y/o ver la respuesta.

Este es un vector de caracteres típico que podríamos querer analizar. Para convertirlo en un conjunto de datos de texto ordenado, primero debemos colocarlo en un data frame.  Ejecuta el código para ver el resultado.

```{r convertir_data_frame, exercise = TRUE, exercise.setup = "vector_texto"}

text_df <- tibble(line = 1:5, text = text)

text_df

```

###

Ya tenemos nuestro limerick en un _tibble_, sin embargo, el texto aún no es compatible con un análisis de texto ordenado. No podemos filtrar las palabras ni contar las que ocurren con mayor frecuencia, ya que cada fila está formada por varias palabras combinadas. Necesitamos convertir este texto para que tenga _un token por documento por fila_.

**Un token es una unidad significativa de texto, generalmente una palabra, que queremos en usar para un análisis más detallado, y la tokenización es el proceso de dividir el texto en tokens.**

En este primer ejemplo, solo tenemos un documento (el limerick), pero en general trabajaremos con datos de varios documentos.

Dentro de nuestro tibble, necesitamos dividir el texto en tokens individuales (un proceso llamado tokenización) y transformarlo en una estructura de datos ordenada. Para hacer esto, usamos la función `unnest_tokens()` del paquete `tidytext`.

Ejecuta el siguiente código para ver como trabaja esta función.

```{r tokenizar, exercise = TRUE, exercise.setup = "convertir_data_frame"}

library(tidytext)

text_df %>%
  unnest_tokens(palabra, text)

```
### La función `unnest_tokens`

Buen trabajo!. El código anterior nos permitió usar dos argumentos básicos de la función `unnest_tokens`: 

* El nombre de la columna que se creará cuando el texto se separe en tokens, en este caso el nombre es _palabra_. 
* La columna de entrada de la que proviene el texto: _text_ en este caso. 

Recordemos que _text_df_ creado en el ejercicio anterior tiene una columna llamada _text_ que contiene los datos de interés.

Después de usar `unnest_tokens`, dividimos cada fila original para que genere una fila por cada token (palabra) en el nuevo tibble; la tokenización predeterminada en `unnest_tokens()` es para palabras individuales, como en este ejemplo. La funcion también hace otras tareas por defecto:

  * Se conservan otras columnas, como el número de línea de donde proviene cada palabra.
  * Se elimina la puntuación (las comas no están más, en este ejemplo).
  * Se convierten los tokens a minúsculas, lo que los hace más fáciles de comparar o combinar con otros conjuntos de datos. (El argumento `to_lower = FALSE` desactiva este comportamiento).

Con los datos de texto en este formato ordenado, podemos procesarlos y visualizarlos usando las herramientas estándar para datos tidy, como `dplyr`, `tidyr` y `ggplot2`.

### Ordenando más limericks

Ahora que sabemos usar esta función vamos a ordenar más limericks de Zoo Loco.  Ejecuta el siguiente código para generar el set de datos de limericks que vamos a usar en el resto de los ejercicios:

```{r limericks, exercise = TRUE}

limericks <- c("Siempre de frac y con zapatos finos,",
              "No parece que fueran argentinos.",
              "por que, por que sera", 
              "Que no usan chiripa", 
              "Ni poncho ni alpargatas los pinguinos?",
              "Un hipopotamo tan chiquitito",
              "Que parezca de lejos un mosquito,",
              "Que se pueda hacer upa",
              "Y mirarlo con lupa,",
              "Debe de ser un hipopotamito",
              "Si un toro, en vez de ser todo de cuero, ",
              "Es de plumas y vuela muy ligero, ",
              "Si tiene dos patitas muy largas y finitas... ",
              "Basta, ya se: no es toro sino tero.",
              "En el medio del mar nada un atun",
              "Estilo mariposa y al tuntun",
              "Nadando a la carrera", 
              "Quizas ganar espera",
              "Si no la maraton, la maratun",
              "Si alguna vez conocen una trucha",
              "Que en un arbol muy alto hizo la cucha,",
              "Que solamente nada",
              "En agua no mojada,",
              "Senores, esa trucha esta enfermucha.",
              "En Tucuman vivia una tortuga",
              "viejisima pero sin una sola arruga,",
              "porque en toda ocasion",
              "tuvo la precaucion",
              "de comer bien planchada la lechuga.")

limericks
```
### Mensaje

¡Muy bien!, ahora tenemos un vector con 29 líneas de texto de cuatro limericks de Zoo Loco.

### Transformando los limericks en un tibble

Teniendo en cuenta los ejercicios anteriores, completa el siguiente código para generar un tibble con los datos, prueba ejecutando el código para ver si funcionó. 

```{r convertir_data_frame_limericks, exercise = TRUE, exercise.setup = "limericks"}

limericks_df <- ____________(line = 1:__, text = text)

limericks_df

```

```{r convertir_data_frame_limericks-hint-1}

Recuerda que la función para generar un data frame se llama tibble.
  
```

```{r convertir_data_frame_limericks-hint-2}

El vector limericks tiene 29 filas.
  
```

```{r convertir_data_frame_limericks-solution}

limericks_df <- tibble(line = 1:29, text = limericks)

limericks_df
  
```

### Mensaje

¡Excelente!, Ya convertiste el vector en un tibble, ahora convirtamos el tibble de los limericks en un conjunto de dato ordenados, donde cada palabra sea una fila.  

Completa el siguiente código para realizar esta tarea.

```{r limericks_tidy, exercise = TRUE, exercise.setup = "limericks"}

limericks_df <- tibble(line = 1:29, text = limericks)

limericks_df <- limericks_df %>%
  __________(__________, text)

limericks_df
```

```{r limericks_tidy-hint}
limericks_df <- tibble(line = 1:29, text = limericks)

limericks_df <- limericks_df %>%
  unnest_tokens(_____________, text)

limericks_df
```

```{r limericks_tidy-solution}
limericks_df <- tibble(line = 1:29, text = limericks)

limericks_df <- limericks_df %>%
  unnest_tokens(palabra, text)

limericks_df
```

### Vamos a contar palabras

¡Buen trabajo! En el tibble `limericks_df` ahora tenemos 161 filas, una por cada palabra que se encontraba en los versos.

Si recorremos el tibble veremos que hay algunas palabras que se repiten, para saber cuantas veces aparece una palabra podemos contarlas.

Y como el texto ahora tiene un formato _tidy_ 




## Fuentes

* Libro Text Minig with R. Julia Silge and David Robinson. https://www.tidytextmining.com/index.html 

* Libro Zoo Loco. María Elena Walsh. https://g.co/kgs/vagz5F

## Licencia

```{r, echo=FALSE, fig.align = "left"}
knitr::include_graphics("images/CC_BY-SA_4.0.png")  
```

Este curso se comparte bajo la licencia [Creative Commons Attribution-ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/deed.es_ES) y fue realizado por [Yanina Bellini Saibene](https://yabellini.netlify.app/)
